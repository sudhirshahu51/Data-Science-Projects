{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Just copy pasted content pdf into a text file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f = open('java.txt', 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f.seek(0)\n",
    "text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25275"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "textlines = text.splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "625"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(textlines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Java Basics',\n",
       " 'Â© 1996-2003 jGuru.com. All Rights Reserved. Java Basics -1',\n",
       " 'Java Basics',\n",
       " 'Topics in this section include:',\n",
       " 'â€¢ What makes Java programs portable, secure, and robust']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "textlines[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "words = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenizing words in each line of document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for line in textlines:\n",
    "    new_words = nltk.word_tokenize(line)\n",
    "    words = words + new_words                                              "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Consider only those words starting from alphabets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "alphabe_words = [w.lower() for w in words if re.search('^[A-Za-z]', w)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['java',\n",
       " 'basics',\n",
       " 'jguru.com',\n",
       " 'all',\n",
       " 'rights',\n",
       " 'reserved',\n",
       " 'java',\n",
       " 'basics',\n",
       " 'java',\n",
       " 'basics']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alphabe_words[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Removing stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stopword = list(stopwords.words('english'))\n",
    "w_words = [w for w in alphabe_words if w not in stopword and len(w) > 2]\n",
    "\n",
    "#print(stopword)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Lemmatizer for converting words in meaningful words in each line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wnlemma = nltk.WordNetLemmatizer()\n",
    "words_lemma = [wnlemma.lemmatize(t) for t in w_words]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating frequency of words in document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.probability import FreqDist\n",
    "dist = FreqDist(words_lemma)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word java have frequency 110\n",
      "Word basic have frequency 48\n",
      "Word jguru.com have frequency 23\n",
      "Word right have frequency 23\n",
      "Word reserved have frequency 22\n",
      "Word topic have frequency 1\n",
      "Word section have frequency 3\n",
      "Word include have frequency 3\n",
      "Word make have frequency 13\n",
      "Word program have frequency 20\n",
      "Word portable have frequency 5\n"
     ]
    }
   ],
   "source": [
    "n = 0\n",
    "for j,f in dist.items():\n",
    "    if n <=10:\n",
    "        print(\"Word {} have frequency {}\".format(j,f))\n",
    "    n +=1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "total=0\n",
    "for i,c in dist.items():\n",
    "    total = total + c\n",
    "for i,c in dist.items():\n",
    "    dist[i] = round(c/total, 6)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sorted_list = sorted(dist.items(), key=lambda i: i[1], reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weights based upon probability of words in doc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('java', 0.047251),\n",
       " ('object', 0.022766),\n",
       " ('new', 0.022337),\n",
       " ('basic', 0.020619),\n",
       " ('button', 0.020619),\n",
       " ('data', 0.018471),\n",
       " ('int', 0.017182),\n",
       " ('applet', 0.016753),\n",
       " ('code', 0.016323),\n",
       " ('method', 0.015464),\n",
       " ('array', 0.014175),\n",
       " ('class', 0.013746),\n",
       " ('string', 0.012027),\n",
       " ('jguru.com', 0.00988),\n",
       " ('right', 0.00988),\n",
       " ('c++', 0.00988),\n",
       " ('reserved', 0.00945),\n",
       " ('example', 0.00945),\n",
       " ('public', 0.00945),\n",
       " ('type', 0.00945)]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_list[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Convert it into the Excel file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import xlsxwriter\n",
    "\n",
    "# Create a workbook and add a worksheet.\n",
    "workbook = xlsxwriter.Workbook('Weight_list.xlsx')\n",
    "worksheet = workbook.add_worksheet()\n",
    "\n",
    "# Some data we want to write to the worksheet.\n",
    "data = sorted_list\n",
    "\n",
    "# Iterate over the data and write it out row by row.\n",
    "for row, line in enumerate(data):\n",
    "    for col, cell in enumerate(line):\n",
    "        worksheet.write(row, col, cell)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Java Basics', 'Â© 1996-2003 jGuru.com. All Rights Reserved. Java Basics -1']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "textlines[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using LDA Approch for obtaining weights of words "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tokenized_array = []\n",
    "for line in textlines:\n",
    "    tokenized_lines = nltk.word_tokenize(line)\n",
    "    tokenized_array.append(tokenized_lines)\n",
    "    \n",
    "    \n",
    "import re\n",
    "alphabe_words_array= []\n",
    "for line in tokenized_array:\n",
    "        alphabe_words = [w.lower() for w in line if re.search('^[A-Za-z]', w)]\n",
    "        alphabe_words_array.append(alphabe_words)\n",
    " \n",
    "from nltk.corpus import stopwords\n",
    "words_array= []\n",
    "stopword = list(stopwords.words('english'))\n",
    "for line in alphabe_words_array:\n",
    "    w_words = [w for w in line if w not in stopword and len(w) > 2]\n",
    "    if len(w_words)> 0:\n",
    "        words_array.append(w_words)\n",
    "\n",
    "#words_array\n",
    "\n",
    "wnlemma = nltk.WordNetLemmatizer()\n",
    "sent_lemma = []\n",
    "for line in words_array:\n",
    "    words_lemma = [wnlemma.lemmatize(t) for t in line]\n",
    "    sent_lemma.append(words_lemma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.037*\"java\" + 0.018*\"object\" + 0.017*\"new\" + 0.016*\"basic\" + 0.016*\"button\" + 0.015*\"data\" + 0.014*\"int\" + 0.013*\"applet\" + 0.013*\"code\" + 0.012*\"method\" + 0.011*\"array\" + 0.011*\"class\" + 0.010*\"string\" + 0.008*\"c++\" + 0.008*\"right\" + 0.008*\"jguru.com\" + 0.008*\"type\" + 0.008*\"public\" + 0.008*\"example\" + 0.008*\"reserved\" + 0.007*\"program\" + 0.006*\"comment\" + 0.006*\"pointer\" + 0.006*\"return\" + 0.006*\"c/c++\" + 0.005*\"language\" + 0.005*\"null\" + 0.005*\"memory\" + 0.005*\"use\" + 0.005*\"primitive\" + 0.005*\"void\" + 0.005*\"operator\" + 0.005*\"make\" + 0.004*\"may\" + 0.004*\"reference\" + 0.004*\"application\" + 0.004*\"browser\" + 0.004*\"element\" + 0.004*\"allocate\" + 0.004*\"garbage\" + 0.004*\"following\" + 0.004*\"system\" + 0.004*\"constant\" + 0.004*\"stack\" + 0.004*\"file\" + 0.004*\"parameter\" + 0.004*\"runtime\" + 0.004*\"variable\" + 0.004*\"would\" + 0.003*\"called\" + 0.003*\"init\" + 0.003*\"two\" + 0.003*\"collection\" + 0.003*\"a.data\" + 0.003*\"statement\" + 0.003*\"byte\" + 0.003*\"definition\" + 0.003*\"bit\" + 0.003*\"one\" + 0.003*\"value\" + 0.003*\"literal\" + 0.003*\"b.data\" + 0.002*\"sizeof\" + 0.002*\"note\" + 0.002*\"refer\" + 0.002*\"thread\" + 0.002*\"main\" + 0.002*\"equivalent\" + 0.002*\"semantics\" + 0.002*\"heap\" + 0.002*\"args\" + 0.002*\"true\" + 0.002*\"instance\" + 0.002*\"import\" + 0.002*\"call\" + 0.002*\"effect\" + 0.002*\"need\" + 0.002*\"using\" + 0.002*\"platform\" + 0.002*\"source\" + 0.002*\"calloc\" + 0.002*\"used\" + 0.002*\"similar\" + 0.002*\"static\" + 0.002*\"library\" + 0.002*\"portable\" + 0.002*\"executed\" + 0.002*\"boolean\" + 0.002*\"point\" + 0.002*\"predefined\" + 0.002*\"passed\" + 0.002*\"expression\" + 0.002*\"foo\" + 0.002*\"execution\" + 0.002*\"width\" + 0.002*\"exception\" + 0.002*\"allocates\" + 0.002*\"equal\" + 0.002*\"consider\" + 0.002*\"blah\"')]"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gensim\n",
    "from gensim import corpora, models\n",
    "dictionary = corpora.Dictionary(sent_lemma) \n",
    "corpus = [dictionary.doc2bow(doc) for doc in sent_lemma]#term matrix\n",
    "ldamodel = gensim.models.ldamodel.LdaModel(corpus, num_topics = 1, id2word = dictionary, passes = 50)\n",
    "ldamodel.print_topics(num_topics= 1,num_words = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
